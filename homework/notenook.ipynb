{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5858dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Empaquetado del entrenamiento del modelo\n",
    "#\n",
    "def train_estimator(alpha=0.5, l1_ratio=0.5, verbose=1):\n",
    "    \"\"\"\n",
    "    # Función completa para entrenar un modelo ElasticNet\n",
    "    # \n",
    "    # Parámetros:\n",
    "    # - alpha: Parámetro de regularización que controla la fuerza de la penalización (default=0.5)\n",
    "    # - l1_ratio: Proporción de penalización L1 frente a L2 (default=0.5)\n",
    "    # - verbose: Si es > 0, imprime métricas de evaluación (default=1)\n",
    "    #\n",
    "    # Esta función:\n",
    "    # 1. Carga datos de vinos desde URL\n",
    "    # 2. Divide los datos en conjuntos de entrenamiento y prueba\n",
    "    # 3. Entrena un modelo ElasticNet con los parámetros proporcionados\n",
    "    # 4. Evalúa el modelo con métricas MSE, MAE y R2\n",
    "    # 5. Guarda el modelo si es mejor que el modelo anteriormente guardado\n",
    "    \"\"\"\n",
    "\n",
    "    import os\n",
    "    import pickle\n",
    "\n",
    "    import pandas as pd\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # Carga de datos desde URL - Dataset de calidad de vinos\n",
    "    url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "    df = pd.read_csv(url, sep=\";\")\n",
    "\n",
    "    # Separación de características (X) y variable objetivo (y)\n",
    "    y = df[\"quality\"]\n",
    "    x = df.copy()\n",
    "    x.pop(\"quality\")\n",
    "\n",
    "    # División de datos en conjuntos de entrenamiento (75%) y prueba (25%)\n",
    "    (x_train, x_test, y_train, y_test) = train_test_split(\n",
    "        x,\n",
    "        y,\n",
    "        test_size=0.25,\n",
    "        random_state=0,\n",
    "    )\n",
    "\n",
    "    # Creación y entrenamiento del modelo ElasticNet\n",
    "    estimator = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=12345)\n",
    "\n",
    "    estimator.fit(x_train, y_train)\n",
    "    y_pred = estimator.predict(x_test)\n",
    "\n",
    "    # Cálculo de métricas de evaluación\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Mostrar métricas si verbose > 0\n",
    "    if verbose > 0:\n",
    "        print(estimator, \":\", sep=\"\")\n",
    "        print(f\"  MSE: {mse}\")\n",
    "        print(f\"  MAE: {mae}\")\n",
    "        print(f\"  R2: {r2}\")\n",
    "\n",
    "    # Comprobar si existe un modelo guardado previamente\n",
    "    if not os.path.exists(\"estimator.pickle\"):\n",
    "        saved_estimator = None\n",
    "    else:\n",
    "        with open(\"estimator.pickle\", \"rb\") as file:\n",
    "            saved_estimator = pickle.load(file)\n",
    "\n",
    "    # Guardar el modelo actual si es mejor que el anterior o si no existe modelo previo\n",
    "    if saved_estimator is None or estimator.score(\n",
    "        x_test, y_test\n",
    "    ) > saved_estimator.score(x_test, y_test):\n",
    "        with open(\"estimator.pickle\", \"wb\") as file:\n",
    "            pickle.dump(estimator, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea67065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet(alpha=0.2, l1_ratio=0.2, random_state=12345):\n",
      "  MSE: 0.43869119518947153\n",
      "  MAE: 0.5236106762028768\n",
      "  R2: 0.2822387414965034\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Experimento\n",
    "#\n",
    "# Prueba del modelo con parámetros específicos:\n",
    "# - alpha = 0.2: Intensidad de regularización moderada-baja\n",
    "# - l1_ratio = 0.2: Mayor peso a la regularización L2 que a la L1\n",
    "train_estimator(0.2, 0.2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1bc325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet(alpha=0.5, random_state=12345):\n",
      "  MSE: 0.5294843132862007\n",
      "  MAE: 0.5894666734018875\n",
      "  R2: 0.13368827268570616\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Experimento\n",
    "#\n",
    "# Prueba del modelo con parámetros diferentes:\n",
    "# - alpha = 0.5: Intensidad de regularización media\n",
    "# - l1_ratio = 0.5: Balance equitativo entre regularización L1 y L2 (ElasticNet balanceado)\n",
    "train_estimator(0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578f53ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.04471258, 5.09836647, 5.20264959, ..., 5.94512405, 5.44101164,\n",
       "       6.07251942], shape=(1599,))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Uso del modelo en productivo\n",
    "#\n",
    "def use_estimator():\n",
    "    \"\"\"\n",
    "    # Función para utilizar el modelo entrenado en un entorno productivo\n",
    "    #\n",
    "    # Esta función:\n",
    "    # 1. Carga datos locales desde un archivo CSV\n",
    "    # 2. Prepara las características (elimina la columna objetivo)\n",
    "    # 3. Carga el modelo guardado anteriormente\n",
    "    # 4. Realiza predicciones con el modelo cargado\n",
    "    # 5. Retorna las predicciones\n",
    "    \"\"\"\n",
    "\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "\n",
    "    # Carga de datos desde archivo local en lugar de URL\n",
    "    # url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "    df = pd.read_csv('data.csv', sep=\";\")\n",
    "\n",
    "    # Separación de características y variable objetivo\n",
    "    y = df[\"quality\"]\n",
    "    x = df.copy()\n",
    "    x.pop(\"quality\")\n",
    "\n",
    "    # Carga del modelo guardado previamente\n",
    "    with open(\"estimator.pickle\", \"rb\") as file:\n",
    "        estimator = pickle.load(file)\n",
    "\n",
    "    # Realización de predicciones con el modelo\n",
    "    y_pred = estimator.predict(x)\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "# Ejecución de la función y obtención de predicciones\n",
    "use_estimator()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bd017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Carga de datos\n",
    "#\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    # Función para cargar los datos del dataset de vinos\n",
    "    #\n",
    "    # Esta función:\n",
    "    # 1. Carga datos desde un archivo CSV local\n",
    "    # 2. Separa los datos en características (X) y variable objetivo (y)\n",
    "    # 3. Retorna las características y la variable objetivo como objetos separados\n",
    "    #\n",
    "    # Returns:\n",
    "    #   x: DataFrame con las características del vino (como acidez, pH, alcohol, etc.)\n",
    "    #   y: Serie con la calidad del vino (variable objetivo a predecir)\n",
    "    \"\"\"\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    # Carga de datos desde archivo local en lugar de URL\n",
    "    # url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "    df = pd.read_csv('data.csv', sep=\";\")\n",
    "\n",
    "    # Separación de variables objetivo y características\n",
    "    y = df[\"quality\"]\n",
    "    x = df.copy()\n",
    "    x.pop(\"quality\")\n",
    "\n",
    "    return x, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342bdcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Particionamiento de datos\n",
    "#\n",
    "def make_train_test_split(x, y):\n",
    "    \"\"\"\n",
    "    # Función para dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    #\n",
    "    # Parámetros:\n",
    "    #   x: DataFrame con las características del conjunto de datos\n",
    "    #   y: Serie con la variable objetivo\n",
    "    #\n",
    "    # Esta función:\n",
    "    # 1. Divide los datos en 75% para entrenamiento y 25% para prueba\n",
    "    # 2. Utiliza una semilla aleatoria fija (random_state=0) para garantizar reproducibilidad\n",
    "    #\n",
    "    # Returns:\n",
    "    #   x_train: Características para entrenamiento\n",
    "    #   x_test: Características para prueba\n",
    "    #   y_train: Variable objetivo para entrenamiento\n",
    "    #   y_test: Variable objetivo para prueba\n",
    "    \"\"\"\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    (x_train, x_test, y_train, y_test) = train_test_split(\n",
    "        x,\n",
    "        y,\n",
    "        test_size=0.25,  # 25% de los datos para prueba\n",
    "        random_state=0,  # Semilla aleatoria fija para reproducibilidad\n",
    "    )\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de04516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de metricas de evaluación\n",
    "#\n",
    "def eval_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    # Función para calcular métricas de evaluación del modelo\n",
    "    #\n",
    "    # Parámetros:\n",
    "    #   y_true: Valores reales de la variable objetivo\n",
    "    #   y_pred: Valores predichos por el modelo\n",
    "    #\n",
    "    # Esta función calcula tres métricas importantes:\n",
    "    # 1. MSE (Mean Squared Error): Error cuadrático medio - mide el promedio de los errores al cuadrado\n",
    "    # 2. MAE (Mean Absolute Error): Error absoluto medio - mide el promedio de los errores absolutos\n",
    "    # 3. R2 (R cuadrado): Coeficiente de determinación - mide la proporción de varianza explicada (1 es perfecto)\n",
    "    #\n",
    "    # Returns:\n",
    "    #   mse, mae, r2: Tupla con las tres métricas calculadas\n",
    "    \"\"\"\n",
    "\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    return mse, mae, r2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0a1616",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Reporte de métricas de evaluación\n",
    "#\n",
    "def report(estimator, mse, mae, r2):\n",
    "    \"\"\"\n",
    "    # Función para imprimir un reporte de las métricas de evaluación del modelo\n",
    "    #\n",
    "    # Parámetros:\n",
    "    #   estimator: Modelo entrenado (para mostrar sus características)\n",
    "    #   mse: Error cuadrático medio\n",
    "    #   mae: Error absoluto medio\n",
    "    #   r2: Coeficiente de determinación R²\n",
    "    #\n",
    "    # Esta función imprime:\n",
    "    # 1. Información sobre el estimador utilizado\n",
    "    # 2. Las tres métricas principales de evaluación (MSE, MAE, R2)\n",
    "    # \n",
    "    # Valores R² más cercanos a 1 indican mejor ajuste del modelo\n",
    "    \"\"\"\n",
    "\n",
    "    print(estimator, \":\", sep=\"\")\n",
    "    print(f\"  MSE: {mse}\")\n",
    "    print(f\"  MAE: {mae}\")\n",
    "    print(f\"  R2: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f13b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Almacenamiento del modelo\n",
    "#\n",
    "def save_best_estimator(estimator):\n",
    "    \"\"\"\n",
    "    # Función para guardar el mejor modelo en disco\n",
    "    #\n",
    "    # Parámetros:\n",
    "    #   estimator: El modelo entrenado que se desea guardar\n",
    "    #\n",
    "    # Esta función:\n",
    "    # 1. Serializa el modelo utilizando la biblioteca pickle\n",
    "    # 2. Guarda el modelo serializado en un archivo llamado \"estimator.pickle\"\n",
    "    # 3. Este archivo puede ser cargado posteriormente para hacer predicciones\n",
    "    #\n",
    "    # El guardado del modelo permite usarlo más tarde sin necesidad de reentrenarlo\n",
    "    \"\"\"\n",
    "\n",
    "    import os\n",
    "    import pickle\n",
    "\n",
    "    with open(\"estimator.pickle\", \"wb\") as file:\n",
    "        pickle.dump(estimator, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58efe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del modelo\n",
    "#\n",
    "def load_best_estimator():\n",
    "    \"\"\"\n",
    "    # Función para cargar el mejor modelo guardado previamente\n",
    "    #\n",
    "    # Esta función:\n",
    "    # 1. Verifica si existe el archivo \"estimator.pickle\" que contiene el modelo\n",
    "    # 2. Si existe, deserializa el modelo usando pickle y lo retorna\n",
    "    # 3. Si no existe, retorna None\n",
    "    #\n",
    "    # Returns:\n",
    "    #   estimator: El modelo cargado, o None si no existe un modelo guardado\n",
    "    #\n",
    "    # Esto permite reutilizar modelos entrenados anteriormente sin necesidad de reentrenarlos\n",
    "    \"\"\"\n",
    "\n",
    "    import os\n",
    "    import pickle\n",
    "\n",
    "    if not os.path.exists(\"estimator.pickle\"):\n",
    "        return None\n",
    "    with open(\"estimator.pickle\", \"rb\") as file:\n",
    "        estimator = pickle.load(file)\n",
    "\n",
    "    return estimator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e350af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "#\n",
    "def train_estimator(alpha=0.5, l1_ratio=0.5, verbose=1):\n",
    "    \"\"\"\n",
    "    # Versión modularizada de la función de entrenamiento del modelo ElasticNet\n",
    "    #\n",
    "    # Parámetros:\n",
    "    #   alpha: Parámetro de regularización (default=0.5)\n",
    "    #   l1_ratio: Proporción de penalización L1 frente a L2 (default=0.5)\n",
    "    #   verbose: Si es > 0, imprime métricas de evaluación (default=1)\n",
    "    #\n",
    "    # Esta función:\n",
    "    # 1. Utiliza funciones auxiliares modularizadas para cada paso del proceso\n",
    "    # 2. Carga los datos, realiza la división train/test\n",
    "    # 3. Entrena el modelo ElasticNet con los parámetros proporcionados\n",
    "    # 4. Evalúa el modelo y opcionalmente reporta las métricas\n",
    "    # 5. Guarda el modelo si es mejor que el modelo previamente guardado\n",
    "    #\n",
    "    # Esta implementación es más modular y mantenible que la original\n",
    "    \"\"\"\n",
    "\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "\n",
    "    x, y = load_data()\n",
    "    x_train, x_test, y_train, y_test = make_train_test_split(x, y)\n",
    "    estimator = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=12345)\n",
    "    estimator.fit(x_train, y_train)\n",
    "    mse, mae, r2 = eval_metrics(y_test, y_pred=estimator.predict(x_test))\n",
    "    if verbose > 0:\n",
    "        report(estimator, mse, mae, r2)\n",
    "\n",
    "    best_estimator = load_best_estimator()\n",
    "    if best_estimator is None or estimator.score(x_test, y_test) > best_estimator.score(\n",
    "        x_test, y_test\n",
    "    ):\n",
    "        best_estimator = estimator\n",
    "\n",
    "    save_best_estimator(best_estimator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c58672b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet(alpha=0.5, random_state=12345):\n",
      "  MSE: 0.5294843132862007\n",
      "  MAE: 0.5894666734018875\n",
      "  R2: 0.13368827268570616\n",
      "ElasticNet(alpha=0.2, l1_ratio=0.2, random_state=12345):\n",
      "  MSE: 0.43869119518947153\n",
      "  MAE: 0.5236106762028768\n",
      "  R2: 0.2822387414965034\n",
      "ElasticNet(alpha=0.1, l1_ratio=0.1, random_state=12345):\n",
      "  MSE: 0.4183271587407731\n",
      "  MAE: 0.5055024368693067\n",
      "  R2: 0.31555720466583137\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "# Experimentación con tres configuraciones diferentes de hiperparámetros\n",
    "# \n",
    "# Probamos tres combinaciones distintas de alpha y l1_ratio:\n",
    "# 1. alpha=0.5, l1_ratio=0.5: Regularización media con balance entre L1 y L2\n",
    "# 2. alpha=0.2, l1_ratio=0.2: Regularización más suave con mayor peso de L2\n",
    "# 3. alpha=0.1, l1_ratio=0.1: Regularización muy suave con mayor peso de L2\n",
    "#\n",
    "# El objetivo es comparar el rendimiento de estas configuraciones\n",
    "# y guardar automáticamente el modelo con mejor desempeño\n",
    "train_estimator(0.5, 0.5)\n",
    "train_estimator(0.2, 0.2)\n",
    "train_estimator(0.1, 0.1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35227c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet(alpha=np.float64(0.0001), l1_ratio=np.float64(0.0001),\n",
      "           random_state=12345):\n",
      "  MSE: 0.40021745821413146\n",
      "  MAE: 0.4848004855172136\n",
      "  R2: 0.34518725328239785\n"
     ]
    }
   ],
   "source": [
    "def check_estimator():\n",
    "    \"\"\"\n",
    "    # Función para verificar el rendimiento del mejor modelo guardado\n",
    "    #\n",
    "    # Esta función:\n",
    "    # 1. Carga los datos y los divide en conjuntos de entrenamiento y prueba\n",
    "    # 2. Carga el mejor modelo guardado (el que obtuvo mejor puntuación)\n",
    "    # 3. Evalúa el modelo con los datos de prueba\n",
    "    # 4. Imprime un reporte con las métricas de rendimiento\n",
    "    #\n",
    "    # Sirve para confirmar cuál es el modelo actual guardado y su rendimiento\n",
    "    \"\"\"\n",
    "\n",
    "    x, y = load_data()\n",
    "    x_train, x_test, y_train, y_test = make_train_test_split(x, y)\n",
    "    estimator = load_best_estimator()\n",
    "    mse, mae, r2 = eval_metrics(y_test, y_pred=estimator.predict(x_test))\n",
    "    report(estimator, mse, mae, r2)\n",
    "\n",
    "\n",
    "#\n",
    "# Debe coincidir con el mejor modelo encontrado en la celdas anteriores\n",
    "#\n",
    "check_estimator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f03c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hyperparameters_search(alphas, l1_ratios):\n",
    "    \"\"\"\n",
    "    # Función para realizar una búsqueda exhaustiva de hiperparámetros\n",
    "    #\n",
    "    # Parámetros:\n",
    "    #   alphas: Lista o array de valores para el parámetro alpha a probar\n",
    "    #   l1_ratios: Lista o array de valores para el parámetro l1_ratio a probar\n",
    "    #\n",
    "    # Esta función:\n",
    "    # 1. Itera sobre todas las combinaciones posibles de alpha y l1_ratio\n",
    "    # 2. Entrena un modelo para cada combinación\n",
    "    # 3. No muestra las métricas de cada modelo (verbose=0)\n",
    "    # 4. Guarda automáticamente el mejor modelo encontrado\n",
    "    #\n",
    "    # La búsqueda de hiperparámetros es una técnica para encontrar la mejor \n",
    "    # configuración de parámetros para maximizar el rendimiento del modelo\n",
    "    \"\"\"\n",
    "\n",
    "    for alpha in alphas:\n",
    "        for l1_ratio in l1_ratios:\n",
    "            train_estimator(alpha=alpha, l1_ratio=l1_ratio, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720370e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet(alpha=np.float64(0.0001), l1_ratio=np.float64(0.0001),\n",
      "           random_state=12345):\n",
      "  MSE: 0.40021745821413146\n",
      "  MAE: 0.4848004855172136\n",
      "  R2: 0.34518725328239785\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Creación de arrays con valores de hiperparámetros a probar\n",
    "# - alphas: 10 valores equidistantes entre 0.0001 y 0.5 para el parámetro de regularización\n",
    "# - l1_ratios: 10 valores equidistantes entre 0.0001 y 0.5 para la proporción L1/L2\n",
    "alphas = np.linspace(0.0001, 0.5, 10)\n",
    "l1_ratios = np.linspace(0.0001, 0.5, 10)\n",
    "\n",
    "# Ejecución de la búsqueda exhaustiva de hiperparámetros\n",
    "# Esto entrenará 10x10=100 modelos diferentes con todas las combinaciones posibles\n",
    "make_hyperparameters_search(alphas, l1_ratios)\n",
    "\n",
    "# Verificación del mejor modelo encontrado durante la búsqueda de hiperparámetros\n",
    "# El modelo guardado debe ser el que obtuvo el mejor rendimiento entre todas las combinaciones\n",
    "check_estimator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145a0442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_estimator(alphas, l1_ratios, n_splits=5, verbose=1):\n",
    "    \"\"\"\n",
    "    # Versión avanzada de entrenamiento usando GridSearchCV para búsqueda automática de hiperparámetros\n",
    "    #\n",
    "    # Parámetros:\n",
    "    #   alphas: Lista o array de valores para alpha a probar\n",
    "    #   l1_ratios: Lista o array de valores para l1_ratio a probar\n",
    "    #   n_splits: Número de divisiones para validación cruzada (default=5)\n",
    "    #   verbose: Si es > 0, imprime métricas de evaluación (default=1)\n",
    "    #\n",
    "    # Esta función:\n",
    "    # 1. Utiliza GridSearchCV que prueba todas las combinaciones posibles de hiperparámetros\n",
    "    # 2. Realiza validación cruzada para evaluar modelos de forma más robusta\n",
    "    # 3. Selecciona automáticamente el mejor modelo entre todas las combinaciones\n",
    "    # 4. Guarda el mejor modelo si supera al modelo anterior\n",
    "    #\n",
    "    # GridSearchCV es más eficiente que la búsqueda manual y provee validación cruzada\n",
    "    \"\"\"\n",
    "\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    x, y = load_data()\n",
    "    x_train, x_test, y_train, y_test = make_train_test_split(x, y)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Búsqueda de parámetros con validación cruzada\n",
    "    #\n",
    "    estimator = GridSearchCV(\n",
    "        estimator=ElasticNet(\n",
    "            random_state=12345,\n",
    "        ),\n",
    "        param_grid={\n",
    "            \"alpha\": alphas,  # Todos los valores de alpha a probar\n",
    "            \"l1_ratio\": l1_ratios,  # Todos los valores de l1_ratio a probar\n",
    "        },\n",
    "        cv=n_splits,  # Número de divisiones para validación cruzada\n",
    "        refit=True,   # Reentrenar con los mejores parámetros\n",
    "        verbose=0,    # No mostrar progreso detallado\n",
    "        return_train_score=False,  # No devolver puntuaciones de entrenamiento\n",
    "    )\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # Entrenamiento del GridSearchCV que prueba todas las combinaciones\n",
    "    estimator.fit(x_train, y_train)\n",
    "\n",
    "    # Extracción del mejor estimador encontrado\n",
    "    estimator = estimator.best_estimator_\n",
    "\n",
    "    # Evaluación del mejor modelo en el conjunto de prueba\n",
    "    mse, mae, r2 = eval_metrics(y_test, y_pred=estimator.predict(x_test))\n",
    "    if verbose > 0:\n",
    "        report(estimator, mse, mae, r2)\n",
    "\n",
    "    # Guarda el modelo si es mejor que el anterior\n",
    "    best_estimator = load_best_estimator()\n",
    "    if best_estimator is None or estimator.score(x_test, y_test) > best_estimator.score(\n",
    "        x_test, y_test\n",
    "    ):\n",
    "        best_estimator = estimator\n",
    "\n",
    "    save_best_estimator(best_estimator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186fdd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet(alpha=np.float64(0.0001), l1_ratio=np.float64(0.0001),\n",
      "           random_state=12345):\n",
      "  MSE: 0.40021745821413146\n",
      "  MAE: 0.4848004855172136\n",
      "  R2: 0.34518725328239785\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "# Ejecución del entrenamiento con GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Ejecutamos la búsqueda de hiperparámetros con GridSearchCV que es más eficiente y robusta\n",
    "# \n",
    "# Parámetros:\n",
    "# - alphas: 10 valores espaciados entre 0.0001 y 0.5 \n",
    "# - l1_ratios: 10 valores espaciados entre 0.0001 y 0.5\n",
    "# - n_splits=5: Validación cruzada con 5 divisiones para evaluar cada combinación\n",
    "# - verbose=1: Mostrar resultados del mejor modelo encontrado\n",
    "#\n",
    "# GridSearchCV probará 10x10=100 combinaciones de hiperparámetros\n",
    "# pero con validación cruzada (5-fold), lo que resulta en 500 modelos entrenados\n",
    "train_estimator(\n",
    "    alphas=np.linspace(0.0001, 0.5, 10),\n",
    "    l1_ratios=np.linspace(0.0001, 0.5, 10),\n",
    "    n_splits=5,\n",
    "    verbose=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951d8600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet(alpha=np.float64(0.0001), l1_ratio=np.float64(0.0001),\n",
      "           random_state=12345):\n",
      "  MSE: 0.40021745821413146\n",
      "  MAE: 0.4848004855172136\n",
      "  R2: 0.34518725328239785\n"
     ]
    }
   ],
   "source": [
    "# Verificación final del mejor modelo encontrado\n",
    "#\n",
    "# Después de todas las búsquedas de hiperparámetros realizadas:\n",
    "# 1. Búsqueda manual con tres combinaciones específicas\n",
    "# 2. Búsqueda exhaustiva con bucles anidados (100 combinaciones)\n",
    "# 3. Búsqueda con GridSearchCV y validación cruzada (500 evaluaciones)\n",
    "#\n",
    "# Esta llamada nos muestra las métricas finales del mejor modelo guardado\n",
    "# y su configuración de hiperparámetros (valores de alpha y l1_ratio)\n",
    "check_estimator()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
